<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>App Elasticsearch Cluster by Zabbix agent</title>
  <link rel="stylesheet" href="/assets/css/styles.css">
  <script src="/assets/js/jquery.min.js"></script>
</head>

<body id="body">
  
  
  
  <a href="https://github.com/zabbix/community-templates/tree/main/Databases/Others/template_app_elasticsearch_cluster_by_zabbix_agent">
    <section class="banner-integrations">
	<div class="w container conference-header" id="training_overview" style="padding-top: 60px; min-height: 150px;">
		<div class="banner-content" style="padding-left: 0; padding-bottom: 16px;">
			<h1 class="h1 center">App Elasticsearch Cluster by Zabbix agent</h1>
		</div>
		<!-- <div class="w container">
			<div class="content text">
				<div class="grid grid-space-category center">
					
					<div class="span">
						<a class="card center category-button" href="" style="color: #25282F">category:search </a>
					</div>
					
					<div class="span">
						<a class="card center category-button" href="" style="color: #25282F">category:services </a>
					</div>
					
					<div class="span">
						<a class="card center category-button" href="" style="color: #25282F">title:Elasticsearch </a>
					</div>
					
				</div>
			</div>
		</div> -->
	</div>
</section>
  </a>
  <div class="w container">
    <h2 class="h2">Available versions</h2>
    <br>
    <div class="tabs-section">
      <div id="integrations_tabs" class="tabs">
        <ul>
          
          
          <li>
            <a class="js_tab" id="ver_5_0" href="#body">ver. 5.0
            </a>
          </li>
          
          <li>
            <a class="js_tab" id="ver_6_0" href="#body">ver. 6.0
            </a>
          </li>
          
          <li>
            <a class="js_tab" id="ver_5_4" href="#body">ver. 5.4
            </a>
          </li>
          
        </ul>
      </div>
    </div>
    <br>
    <br>
    
    
    <div id="content_ver_5_0" class="readme">
      <div class="banner-buttons " style="padding-top: 20px; ">
        <a class="button button-gray" style="color: #ffff;" href="/#databases-others-template-app-elasticsearch-cluster-by-zabbix-agent">Back to index</a>
        <a class="button button-green" style="color: #ffff;" href="https://raw.githubusercontent.com/zabbix/community-templates/main/Databases/Others/template_app_elasticsearch_cluster_by_zabbix_agent/5.0/template_app_elasticsearch_cluster_by_zabbix_agent.xml">Download</a>
      </div>
      
      



<h1 id="app-elasticsearch-cluster-by-zabbix-agent">App Elasticsearch Cluster by Zabbix agent</h1>

<h2 id="description">Description</h2>

<p>This is the “Zabbix agent” version of the Elasticsearch template which ships with Zabbix 5.0 - Evren Yurtesen The template to monitor Elasticsearch by Zabbix that work without any external scripts. It works with both standalone and cluster instances. The metrics are collected in one pass remotely using an HTTP agent. They are getting values from REST API _cluster/health, _cluster/stats, _nodes/stats requests. You can set {$ELASTICSEARCH.USERNAME} and {$ELASTICSEARCH.PASSWORD} macros in the template for using on the host level. If you use an atypical location ES API, don’t forget to change the macros {$ELASTICSEARCH.SCHEME}, {$ELASTICSEARCH.HOST},{$ELASTICSEARCH.PORT}. You can discuss this template or leave feedback on our forum https://www.zabbix.com/forum/zabbix-suggestions-and-feedback/399473-discussion-thread-for-official-zabbix-template-for-elasticsearch Template tooling version used: 0.35</p>

<h2 id="overview">Overview</h2>

<p>This is the “Zabbix agent” version of the HTTP template shipped with Zabbix 5.0 (<a href="https://www.zabbix.com/integrations/elasticsearch">https://www.zabbix.com/integrations/elasticsearch</a>)</p>

<p>This version can connect to elasticsearch on localohost or a remote network using the zabbix agent.</p>

<p>I have added checking of read-only indices. Elasticsearch makes indices read only if there is too little disk space. Also added collection of cluster_name as an item.</p>

<p>Please report issues at GitHub (easier to track progress there!)</p>

<p>https://github.com/yurtesen/zabbix_elasticsearch</p>

<p>Evren Yurtesen</p>

<h2 id="author">Author</h2>

<p>Evren Yurtesen</p>

<h2 id="macros-used">Macros used</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Default</th>
      <th>Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>{$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of fetch latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of flush latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HEAP_USED.MAX.CRIT}</td>
      <td>&lt;p&gt;The maximum percent in the use of JVM heap for critically trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">95</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HEAP_USED.MAX.WARN}</td>
      <td>&lt;p&gt;The maximum percent in the use of JVM heap for warning trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">85</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HOST}</td>
      <td>&lt;p&gt;The hostname of the Elasticsearch host.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">localhost</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of indexing latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.PASSWORD}</td>
      <td>&lt;p&gt;The password of the Elasticsearch.&lt;/p&gt;</td>
      <td>``</td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.PORT}</td>
      <td>&lt;p&gt;The port of the Elasticsearch host.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">9200</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of query latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.RESPONSE_TIME.MAX.WARN}</td>
      <td>&lt;p&gt;The ES cluster maximum response time in seconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">10s</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.SCHEME}</td>
      <td>&lt;p&gt;The scheme of the Elasticsearch (http/https).&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">http</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.USERNAME}</td>
      <td>&lt;p&gt;The username of the Elasticsearch.&lt;/p&gt;</td>
      <td>``</td>
      <td>Text macro</td>
    </tr>
  </tbody>
</table>

<h2 id="template-links">Template links</h2>

<p>There are no template links in this template.</p>

<h2 id="discovery-rules">Discovery rules</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Type</th>
      <th>Key and additional info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Index settings discovery</td>
      <td>&lt;p&gt;Discovery ES index settings&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.index.settings&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>Cluster nodes discovery</td>
      <td>&lt;p&gt;Discovery ES cluster nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_nodes/_all/nodes,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1h&lt;/p&gt;</td>
    </tr>
  </tbody>
</table>

<h2 id="items-collected">Items collected</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Type</th>
      <th>Key and additional info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ES: Indices with shards assigned to nodes</td>
      <td>&lt;p&gt;The total number of indices with shards assigned to the selected nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.indices.count&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of data nodes</td>
      <td>&lt;p&gt;The number of nodes that are dedicated to data nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_data_nodes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of relocating shards</td>
      <td>&lt;p&gt;The number of shards that are under relocation.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.relocating_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of non-deleted documents</td>
      <td>&lt;p&gt;The total number of non-deleted documents across all primary shards assigned to the selected nodes. This number is based on the documents in Lucene segments and may include the documents from nested fields.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.indices.docs.count&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster name</td>
      <td>&lt;p&gt;Name of the cluster this node belongs to.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster_name[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get cluster stats</td>
      <td>&lt;p&gt;Returns cluster statistics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_cluster/stats,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of pending tasks</td>
      <td>&lt;p&gt;The number of cluster-level changes that have not yet been executed.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_pending_tasks&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the data role</td>
      <td>&lt;p&gt;The number of selected nodes with the data role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.data&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Service response time</td>
      <td>&lt;p&gt;Checks performance of the TCP service.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>net.tcp.service.perf[”{$ELASTICSEARCH.SCHEME}”,”{$ELASTICSEARCH.HOST}”,”{$ELASTICSEARCH.PORT}”]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of initializing shards</td>
      <td>&lt;p&gt;The number of shards that are under initialization.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.initializing_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of unassigned shards</td>
      <td>&lt;p&gt;The number of shards that are not allocated.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.unassigned_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get cluster health</td>
      <td>&lt;p&gt;Returns the health status of a cluster.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_cluster/health?timeout=5s,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get nodes stats</td>
      <td>&lt;p&gt;Returns cluster nodes statistics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_nodes/stats,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster uptime</td>
      <td>&lt;p&gt;Uptime duration in seconds since JVM has last started.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.jvm.max_uptime[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the master role</td>
      <td>&lt;p&gt;The number of selected nodes with the master role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.master&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Delayed unassigned shards</td>
      <td>&lt;p&gt;The number of shards whose allocation has been delayed by the timeout settings.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.delayed_unassigned_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Inactive shards percentage</td>
      <td>&lt;p&gt;The ratio of inactive shards in the cluster expressed as a percentage.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.inactive_shards_percent_as_number&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of nodes</td>
      <td>&lt;p&gt;The number of nodes within the cluster.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_nodes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get index settings</td>
      <td>&lt;p&gt;Returns index settings.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_settings,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the ingest role</td>
      <td>&lt;p&gt;The number of selected nodes with the ingest role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.ingest&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Total available size to JVM in all file stores</td>
      <td>&lt;p&gt;The total number of bytes available to JVM in the file stores across all selected nodes. Depending on OS or process-level restrictions, this number may be less than nodes.fs.free_in_byes. This is the actual amount of free disk space the selected Elasticsearch nodes can use.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.fs.available_in_bytes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster health status</td>
      <td>&lt;p&gt;Health status of the cluster, based on the state of its primary and replica shards. Statuses are: green All shards are assigned. yellow All primary shards are assigned, but one or more replica shards are unassigned. If a node in the cluster fails, some data could be unavailable until that node is repaired. red One or more primary shards are unassigned, so some data is unavailable. This can occur briefly during cluster startup as primary shards are assigned.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.status&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Service status</td>
      <td>&lt;p&gt;Checks if the service is running and accepting TCP connections.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>net.tcp.service[”{$ELASTICSEARCH.SCHEME}”,”{$ELASTICSEARCH.HOST}”,”{$ELASTICSEARCH.PORT}”]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Task max waiting in queue</td>
      <td>&lt;p&gt;The time expressed in seconds since the earliest initiated task is waiting for being performed.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.task_max_waiting_in_queue&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Total size of all file stores</td>
      <td>&lt;p&gt;The total size in bytes of all file stores across all selected nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.fs.total_in_bytes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.INDEX_NAME}: read_only_allow_delete</td>
      <td>&lt;p&gt;Elasticsearch enforces a read-only index block (index.blocks.read_only_allow_delete) on every index that has one or more shards allocated on the node that has at least one disk exceeding the flood stage.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.index.read_only_allow_delete[{#ES.INDEX_NAME}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency</td>
      <td>&lt;p&gt;The average flush latency calculated from the available flush.total and flush.total_time_in_millis metrics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.flush.latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency</td>
      <td>&lt;p&gt;The average fetch latency calculated by sampling the total number of fetches and the total elapsed time at regular intervals.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.search.fetch_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency</td>
      <td>&lt;p&gt;The average indexing latency calculated from the available index_total and index_time_in_millis metrics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.indexing.index_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency</td>
      <td>&lt;p&gt;The average query latency calculated by sampling the total number of queries and the total elapsed time at regular intervals.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.search.query_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total available size</td>
      <td>&lt;p&gt;The total number of bytes available to this Java virtual machine on all file stores. Depending on OS or process level restrictions, this might appear less than fs.total.free_in_bytes. This is the actual amount of free disk space the Elasticsearch node can utilize.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.fs.total.available_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the refresh thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing query</td>
      <td>&lt;p&gt;Time in milliseconds spent performing query operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of query</td>
      <td>&lt;p&gt;The total number of query operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Amount of JVM heap committed</td>
      <td>&lt;p&gt;The amount of memory, in bytes, available for use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_committed_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Maximum JVM memory available for use</td>
      <td>&lt;p&gt;The maximum amount of memory, in bytes, available for use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_max_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Amount of JVM heap currently in use</td>
      <td>&lt;p&gt;The memory, in bytes, currently in use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_used_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap currently in use</td>
      <td>&lt;p&gt;The percentage of memory currently in use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_used_percent[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node uptime</td>
      <td>&lt;p&gt;JVM uptime in seconds.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.uptime[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the refresh thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the refresh thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the search thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the search thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the search thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the write thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the write thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the write thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing query</td>
      <td>&lt;p&gt;Time in seconds spent performing query operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of queries</td>
      <td>&lt;p&gt;The number of query operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current query operations</td>
      <td>&lt;p&gt;The number of query operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.throttle_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Number of open HTTP connections</td>
      <td>&lt;p&gt;The number of currently open HTTP connections for the node.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.http.current_open[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of HTTP connections opened</td>
      <td>&lt;p&gt;The number of HTTP connections opened for the node per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.http.opened.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of index flushes to disk</td>
      <td>&lt;p&gt;The total number of flush operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.flush.total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent on flushing indices to disk</td>
      <td>&lt;p&gt;Total time in milliseconds spent performing flush operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.flush.total_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current indexing operations</td>
      <td>&lt;p&gt;The number of indexing operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing indexing</td>
      <td>&lt;p&gt;Total time in milliseconds spent performing indexing operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of indexing</td>
      <td>&lt;p&gt;The total number of indexing operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling merge operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling merge operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.merges.total_throttled_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total size</td>
      <td>&lt;p&gt;Total size (in bytes) of all file stores.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.fs.total.total_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling recovery operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling recovery operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.recovery.throttle_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of index refreshes</td>
      <td>&lt;p&gt;The number of refresh operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.refresh.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing refresh</td>
      <td>&lt;p&gt;Time in seconds spent performing refresh operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.refresh.time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of fetch</td>
      <td>&lt;p&gt;The number of fetch operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current fetch operations</td>
      <td>&lt;p&gt;The number of fetch operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing fetch</td>
      <td>&lt;p&gt;Time in seconds spent performing fetch operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing fetch</td>
      <td>&lt;p&gt;Time in milliseconds spent performing fetch operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of fetch</td>
      <td>&lt;p&gt;The total number of fetch operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
  </tbody>
</table>

<h2 id="triggers">Triggers</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Expression</th>
      <th>Priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Read-only index “{#ES.INDEX_NAME}”</td>
      <td>&lt;p&gt;The index setting index.read_only_allow_delete is set to true when the index and index metadata are read only. It is set to false when ES allows writes and metadata changes. ES allows deleting the index to free up resources even when this setting is set to true.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.index.read_only_allow_delete[{#ES.INDEX_NAME}].last()}=1&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency is too high (over {$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If you see this metric increasing steadily, it may indicate a problem with slow disks; this problem may escalate and eventually prevent you from being able to add new information to your index.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.flush.latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency is too high (over {$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If the latency is increasing, it may indicate that you are indexing too many documents at the same time (Elasticsearch’s documentation recommends starting with a bulk indexing size of 5 to 15 megabytes and increasing slowly from there).&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.indexing.index_latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency is too high (over {$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;The fetch phase should typically take much less time than the query phase. If you notice this metric consistently increasing, this could indicate a problem with slow disks, enriching of documents (highlighting the relevant text in search results, etc.), or requesting too many results.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.search.fetch_latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency is too high (over {$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If latency exceeds a threshold, look for potential resource bottlenecks, or investigate whether you need to optimize your queries.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.search.query_latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is critical (over {$ELASTICSEARCH.HEAP_USED.MAX.CRIT}% for 1h)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.jvm.mem.heap_used_percent[{#ES.NODE}].min(1h)}&gt;95&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is high (over {$ELASTICSEARCH.HEAP_USED.MAX.WARN}% for 1h)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.jvm.mem.heap_used_percent[{#ES.NODE}].min(1h)}&gt;85&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node {#ES.NODE} has been restarted (uptime &lt; 10m)</td>
      <td>&lt;p&gt;Uptime is less than 10 minutes&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.jvm.uptime[{#ES.NODE}].last()}&lt;10m&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>information</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}].min(5m)}&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.thread_pool.search.rejected.rate[{#ES.NODE}].min(5m)}&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.thread_pool.write.rejected.rate[{#ES.NODE}].min(5m)}&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>Read-only index “{#ES.INDEX_NAME}” (LLD)</td>
      <td>&lt;p&gt;The index setting index.read_only_allow_delete is set to true when the index and index metadata are read only. It is set to false when ES allows writes and metadata changes. ES allows deleting the index to free up resources even when this setting is set to true.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.index.read_only_allow_delete[{#ES.INDEX_NAME}].last()}=1&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency is too high (over {$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If you see this metric increasing steadily, it may indicate a problem with slow disks; this problem may escalate and eventually prevent you from being able to add new information to your index.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.flush.latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency is too high (over {$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If the latency is increasing, it may indicate that you are indexing too many documents at the same time (Elasticsearch’s documentation recommends starting with a bulk indexing size of 5 to 15 megabytes and increasing slowly from there).&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.indexing.index_latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency is too high (over {$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;The fetch phase should typically take much less time than the query phase. If you notice this metric consistently increasing, this could indicate a problem with slow disks, enriching of documents (highlighting the relevant text in search results, etc.), or requesting too many results.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.search.fetch_latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency is too high (over {$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If latency exceeds a threshold, look for potential resource bottlenecks, or investigate whether you need to optimize your queries.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.indices.search.query_latency[{#ES.NODE}].min(5m)}&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is critical (over {$ELASTICSEARCH.HEAP_USED.MAX.CRIT}% for 1h) (LLD)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.jvm.mem.heap_used_percent[{#ES.NODE}].min(1h)}&gt;95&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is high (over {$ELASTICSEARCH.HEAP_USED.MAX.WARN}% for 1h) (LLD)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.jvm.mem.heap_used_percent[{#ES.NODE}].min(1h)}&gt;85&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node {#ES.NODE} has been restarted (uptime &lt; 10m) (LLD)</td>
      <td>&lt;p&gt;Uptime is less than 10 minutes&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.jvm.uptime[{#ES.NODE}].last()}&lt;10m&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>information</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}].min(5m)}&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.thread_pool.search.rejected.rate[{#ES.NODE}].min(5m)}&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: {App Elasticsearch Cluster by Zabbix agent:es.node.thread_pool.write.rejected.rate[{#ES.NODE}].min(5m)}&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
  </tbody>
</table>


    </div>
    
    
    <div id="content_ver_6_0" class="readme">
      <div class="banner-buttons " style="padding-top: 20px; ">
        <a class="button button-gray" style="color: #ffff;" href="/#databases-others-template-app-elasticsearch-cluster-by-zabbix-agent">Back to index</a>
        <a class="button button-green" style="color: #ffff;" href="https://raw.githubusercontent.com/zabbix/community-templates/main/Databases/Others/template_app_elasticsearch_cluster_by_zabbix_agent/6.0/template_app_elasticsearch_cluster_by_zabbix_agent.yaml">Download</a>
      </div>
      
      



<h1 id="app-elasticsearch-cluster-by-zabbix-agent">App Elasticsearch Cluster by Zabbix agent</h1>

<h2 id="description">Description</h2>

<p>This is the “Zabbix agent” version of the Elasticsearch template which ships with Zabbix 5.0 - Evren Yurtesen The template to monitor Elasticsearch by Zabbix that work without any external scripts. It works with both standalone and cluster instances. The metrics are collected in one pass remotely using an HTTP agent. They are getting values from REST API _cluster/health, _cluster/stats, _nodes/stats requests. You can set {$ELASTICSEARCH.USERNAME} and {$ELASTICSEARCH.PASSWORD} macros in the template for using on the host level. If you use an atypical location ES API, don’t forget to change the macros {$ELASTICSEARCH.SCHEME}, {$ELASTICSEARCH.HOST},{$ELASTICSEARCH.PORT}. You can discuss this template or leave feedback on our forum https://www.zabbix.com/forum/zabbix-suggestions-and-feedback/399473-discussion-thread-for-official-zabbix-template-for-elasticsearch Template tooling version used: 0.35</p>

<h2 id="overview">Overview</h2>

<p>This is the “Zabbix agent” version of the HTTP template shipped with Zabbix 5.0 (<a href="https://www.zabbix.com/integrations/elasticsearch">https://www.zabbix.com/integrations/elasticsearch</a>)</p>

<p>This version can connect to elasticsearch on localohost or a remote network using the zabbix agent.</p>

<p>I have added checking of read-only indices. Elasticsearch makes indices read only if there is too little disk space. Also added collection of cluster_name as an item.</p>

<p>Please report issues at GitHub (easier to track progress there!)</p>

<p>https://github.com/yurtesen/zabbix_elasticsearch</p>

<p>Evren Yurtesen</p>

<h2 id="author">Author</h2>

<p>Evren Yurtesen</p>

<h2 id="macros-used">Macros used</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Default</th>
      <th>Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>{$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of fetch latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of flush latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HEAP_USED.MAX.CRIT}</td>
      <td>&lt;p&gt;The maximum percent in the use of JVM heap for critically trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">95</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HEAP_USED.MAX.WARN}</td>
      <td>&lt;p&gt;The maximum percent in the use of JVM heap for warning trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">85</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HOST}</td>
      <td>&lt;p&gt;The hostname of the Elasticsearch host.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">localhost</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of indexing latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.PASSWORD}</td>
      <td>&lt;p&gt;The password of the Elasticsearch.&lt;/p&gt;</td>
      <td>``</td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.PORT}</td>
      <td>&lt;p&gt;The port of the Elasticsearch host.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">9200</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of query latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.RESPONSE_TIME.MAX.WARN}</td>
      <td>&lt;p&gt;The ES cluster maximum response time in seconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">10s</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.SCHEME}</td>
      <td>&lt;p&gt;The scheme of the Elasticsearch (http/https).&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">http</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.USERNAME}</td>
      <td>&lt;p&gt;The username of the Elasticsearch.&lt;/p&gt;</td>
      <td>``</td>
      <td>Text macro</td>
    </tr>
  </tbody>
</table>

<h2 id="template-links">Template links</h2>

<p>There are no template links in this template.</p>

<h2 id="discovery-rules">Discovery rules</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Type</th>
      <th>Key and additional info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cluster nodes discovery</td>
      <td>&lt;p&gt;Discovery ES cluster nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_nodes/_all/nodes,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1h&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>Index settings discovery</td>
      <td>&lt;p&gt;Discovery ES index settings&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.index.settings&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
  </tbody>
</table>

<h2 id="items-collected">Items collected</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Type</th>
      <th>Key and additional info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ES: Number of non-deleted documents</td>
      <td>&lt;p&gt;The total number of non-deleted documents across all primary shards assigned to the selected nodes. This number is based on the documents in Lucene segments and may include the documents from nested fields.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.indices.docs.count&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get index settings</td>
      <td>&lt;p&gt;Returns index settings.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_settings,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the master role</td>
      <td>&lt;p&gt;The number of selected nodes with the master role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.master&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of data nodes</td>
      <td>&lt;p&gt;The number of nodes that are dedicated to data nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_data_nodes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get cluster health</td>
      <td>&lt;p&gt;Returns the health status of a cluster.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_cluster/health?timeout=5s,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get cluster stats</td>
      <td>&lt;p&gt;Returns cluster statistics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_cluster/stats,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Service status</td>
      <td>&lt;p&gt;Checks if the service is running and accepting TCP connections.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>net.tcp.service[”{$ELASTICSEARCH.SCHEME}”,”{$ELASTICSEARCH.HOST}”,”{$ELASTICSEARCH.PORT}”]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Task max waiting in queue</td>
      <td>&lt;p&gt;The time expressed in seconds since the earliest initiated task is waiting for being performed.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.task_max_waiting_in_queue&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster health status</td>
      <td>&lt;p&gt;Health status of the cluster, based on the state of its primary and replica shards. Statuses are: green All shards are assigned. yellow All primary shards are assigned, but one or more replica shards are unassigned. If a node in the cluster fails, some data could be unavailable until that node is repaired. red One or more primary shards are unassigned, so some data is unavailable. This can occur briefly during cluster startup as primary shards are assigned.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.status&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Total available size to JVM in all file stores</td>
      <td>&lt;p&gt;The total number of bytes available to JVM in the file stores across all selected nodes. Depending on OS or process-level restrictions, this number may be less than nodes.fs.free_in_byes. This is the actual amount of free disk space the selected Elasticsearch nodes can use.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.fs.available_in_bytes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of unassigned shards</td>
      <td>&lt;p&gt;The number of shards that are not allocated.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.unassigned_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster uptime</td>
      <td>&lt;p&gt;Uptime duration in seconds since JVM has last started.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.jvm.max_uptime[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Total size of all file stores</td>
      <td>&lt;p&gt;The total size in bytes of all file stores across all selected nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.fs.total_in_bytes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Service response time</td>
      <td>&lt;p&gt;Checks performance of the TCP service.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>net.tcp.service.perf[”{$ELASTICSEARCH.SCHEME}”,”{$ELASTICSEARCH.HOST}”,”{$ELASTICSEARCH.PORT}”]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of pending tasks</td>
      <td>&lt;p&gt;The number of cluster-level changes that have not yet been executed.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_pending_tasks&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of nodes</td>
      <td>&lt;p&gt;The number of nodes within the cluster.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_nodes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Delayed unassigned shards</td>
      <td>&lt;p&gt;The number of shards whose allocation has been delayed by the timeout settings.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.delayed_unassigned_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of relocating shards</td>
      <td>&lt;p&gt;The number of shards that are under relocation.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.relocating_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the ingest role</td>
      <td>&lt;p&gt;The number of selected nodes with the ingest role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.ingest&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of initializing shards</td>
      <td>&lt;p&gt;The number of shards that are under initialization.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.initializing_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Inactive shards percentage</td>
      <td>&lt;p&gt;The ratio of inactive shards in the cluster expressed as a percentage.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.inactive_shards_percent_as_number&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Indices with shards assigned to nodes</td>
      <td>&lt;p&gt;The total number of indices with shards assigned to the selected nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.indices.count&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster name</td>
      <td>&lt;p&gt;Name of the cluster this node belongs to.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster_name[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get nodes stats</td>
      <td>&lt;p&gt;Returns cluster nodes statistics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_nodes/stats,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the data role</td>
      <td>&lt;p&gt;The number of selected nodes with the data role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.data&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency</td>
      <td>&lt;p&gt;The average flush latency calculated from the available flush.total and flush.total_time_in_millis metrics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.flush.latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency</td>
      <td>&lt;p&gt;The average fetch latency calculated by sampling the total number of fetches and the total elapsed time at regular intervals.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.search.fetch_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency</td>
      <td>&lt;p&gt;The average indexing latency calculated from the available index_total and index_time_in_millis metrics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.indexing.index_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency</td>
      <td>&lt;p&gt;The average query latency calculated by sampling the total number of queries and the total elapsed time at regular intervals.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.search.query_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total available size</td>
      <td>&lt;p&gt;The total number of bytes available to this Java virtual machine on all file stores. Depending on OS or process level restrictions, this might appear less than fs.total.free_in_bytes. This is the actual amount of free disk space the Elasticsearch node can utilize.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.fs.total.available_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the refresh thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing query</td>
      <td>&lt;p&gt;Time in milliseconds spent performing query operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of query</td>
      <td>&lt;p&gt;The total number of query operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Amount of JVM heap committed</td>
      <td>&lt;p&gt;The amount of memory, in bytes, available for use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_committed_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Maximum JVM memory available for use</td>
      <td>&lt;p&gt;The maximum amount of memory, in bytes, available for use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_max_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Amount of JVM heap currently in use</td>
      <td>&lt;p&gt;The memory, in bytes, currently in use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_used_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap currently in use</td>
      <td>&lt;p&gt;The percentage of memory currently in use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_used_percent[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node uptime</td>
      <td>&lt;p&gt;JVM uptime in seconds.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.uptime[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the refresh thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the refresh thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the search thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the search thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the search thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the write thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the write thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the write thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing query</td>
      <td>&lt;p&gt;Time in seconds spent performing query operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of queries</td>
      <td>&lt;p&gt;The number of query operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current query operations</td>
      <td>&lt;p&gt;The number of query operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.throttle_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Number of open HTTP connections</td>
      <td>&lt;p&gt;The number of currently open HTTP connections for the node.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.http.current_open[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of HTTP connections opened</td>
      <td>&lt;p&gt;The number of HTTP connections opened for the node per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.http.opened.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of index flushes to disk</td>
      <td>&lt;p&gt;The total number of flush operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.flush.total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent on flushing indices to disk</td>
      <td>&lt;p&gt;Total time in milliseconds spent performing flush operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.flush.total_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current indexing operations</td>
      <td>&lt;p&gt;The number of indexing operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing indexing</td>
      <td>&lt;p&gt;Total time in milliseconds spent performing indexing operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of indexing</td>
      <td>&lt;p&gt;The total number of indexing operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling merge operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling merge operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.merges.total_throttled_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total size</td>
      <td>&lt;p&gt;Total size (in bytes) of all file stores.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.fs.total.total_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling recovery operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling recovery operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.recovery.throttle_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of index refreshes</td>
      <td>&lt;p&gt;The number of refresh operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.refresh.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing refresh</td>
      <td>&lt;p&gt;Time in seconds spent performing refresh operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.refresh.time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of fetch</td>
      <td>&lt;p&gt;The number of fetch operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current fetch operations</td>
      <td>&lt;p&gt;The number of fetch operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing fetch</td>
      <td>&lt;p&gt;Time in seconds spent performing fetch operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing fetch</td>
      <td>&lt;p&gt;Time in milliseconds spent performing fetch operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of fetch</td>
      <td>&lt;p&gt;The total number of fetch operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.INDEX_NAME}: read_only_allow_delete</td>
      <td>&lt;p&gt;Elasticsearch enforces a read-only index block (index.blocks.read_only_allow_delete) on every index that has one or more shards allocated on the node that has at least one disk exceeding the flood stage.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.index.read_only_allow_delete[{#ES.INDEX_NAME}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
  </tbody>
</table>

<h2 id="triggers">Triggers</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Expression</th>
      <th>Priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Read-only index “{#ES.INDEX_NAME}”</td>
      <td>&lt;p&gt;The index setting index.read_only_allow_delete is set to true when the index and index metadata are read only. It is set to false when ES allows writes and metadata changes. ES allows deleting the index to free up resources even when this setting is set to true.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.index.read_only_allow_delete[{#ES.INDEX_NAME}])=1&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency is too high (over {$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If you see this metric increasing steadily, it may indicate a problem with slow disks; this problem may escalate and eventually prevent you from being able to add new information to your index.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.flush.latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency is too high (over {$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If the latency is increasing, it may indicate that you are indexing too many documents at the same time (Elasticsearch’s documentation recommends starting with a bulk indexing size of 5 to 15 megabytes and increasing slowly from there).&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.indexing.index_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency is too high (over {$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;The fetch phase should typically take much less time than the query phase. If you notice this metric consistently increasing, this could indicate a problem with slow disks, enriching of documents (highlighting the relevant text in search results, etc.), or requesting too many results.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.fetch_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency is too high (over {$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If latency exceeds a threshold, look for potential resource bottlenecks, or investigate whether you need to optimize your queries.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.query_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is critical (over {$ELASTICSEARCH.HEAP_USED.MAX.CRIT}% for 1h)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;95&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is high (over {$ELASTICSEARCH.HEAP_USED.MAX.WARN}% for 1h)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;85&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node {#ES.NODE} has been restarted (uptime &lt; 10m)</td>
      <td>&lt;p&gt;Uptime is less than 10 minutes&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.uptime[{#ES.NODE}])&lt;10m&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>information</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.search.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.write.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency is too high (over {$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If you see this metric increasing steadily, it may indicate a problem with slow disks; this problem may escalate and eventually prevent you from being able to add new information to your index.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.flush.latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency is too high (over {$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If the latency is increasing, it may indicate that you are indexing too many documents at the same time (Elasticsearch’s documentation recommends starting with a bulk indexing size of 5 to 15 megabytes and increasing slowly from there).&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.indexing.index_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency is too high (over {$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;The fetch phase should typically take much less time than the query phase. If you notice this metric consistently increasing, this could indicate a problem with slow disks, enriching of documents (highlighting the relevant text in search results, etc.), or requesting too many results.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.fetch_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency is too high (over {$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If latency exceeds a threshold, look for potential resource bottlenecks, or investigate whether you need to optimize your queries.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.query_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is critical (over {$ELASTICSEARCH.HEAP_USED.MAX.CRIT}% for 1h) (LLD)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;95&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is high (over {$ELASTICSEARCH.HEAP_USED.MAX.WARN}% for 1h) (LLD)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;85&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node {#ES.NODE} has been restarted (uptime &lt; 10m) (LLD)</td>
      <td>&lt;p&gt;Uptime is less than 10 minutes&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.uptime[{#ES.NODE}])&lt;10m&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>information</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.search.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.write.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>Read-only index “{#ES.INDEX_NAME}” (LLD)</td>
      <td>&lt;p&gt;The index setting index.read_only_allow_delete is set to true when the index and index metadata are read only. It is set to false when ES allows writes and metadata changes. ES allows deleting the index to free up resources even when this setting is set to true.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.index.read_only_allow_delete[{#ES.INDEX_NAME}])=1&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
  </tbody>
</table>


    </div>
    
    
    <div id="content_ver_5_4" class="readme">
      <div class="banner-buttons " style="padding-top: 20px; ">
        <a class="button button-gray" style="color: #ffff;" href="/#databases-others-template-app-elasticsearch-cluster-by-zabbix-agent">Back to index</a>
        <a class="button button-green" style="color: #ffff;" href="https://raw.githubusercontent.com/zabbix/community-templates/main/Databases/Others/template_app_elasticsearch_cluster_by_zabbix_agent/5.4/template_app_elasticsearch_cluster_by_zabbix_agent.yaml">Download</a>
      </div>
      
      



<h1 id="app-elasticsearch-cluster-by-zabbix-agent">App Elasticsearch Cluster by Zabbix agent</h1>

<h2 id="description">Description</h2>

<p>This is the “Zabbix agent” version of the Elasticsearch template which ships with Zabbix 5.0 - Evren Yurtesen The template to monitor Elasticsearch by Zabbix that work without any external scripts. It works with both standalone and cluster instances. The metrics are collected in one pass remotely using an HTTP agent. They are getting values from REST API _cluster/health, _cluster/stats, _nodes/stats requests. You can set {$ELASTICSEARCH.USERNAME} and {$ELASTICSEARCH.PASSWORD} macros in the template for using on the host level. If you use an atypical location ES API, don’t forget to change the macros {$ELASTICSEARCH.SCHEME}, {$ELASTICSEARCH.HOST},{$ELASTICSEARCH.PORT}. You can discuss this template or leave feedback on our forum https://www.zabbix.com/forum/zabbix-suggestions-and-feedback/399473-discussion-thread-for-official-zabbix-template-for-elasticsearch Template tooling version used: 0.35</p>

<h2 id="overview">Overview</h2>

<p>This is the “Zabbix agent” version of the HTTP template shipped with Zabbix 5.0 (<a href="https://www.zabbix.com/integrations/elasticsearch">https://www.zabbix.com/integrations/elasticsearch</a>)</p>

<p>This version can connect to elasticsearch on localohost or a remote network using the zabbix agent.</p>

<p>I have added checking of read-only indices. Elasticsearch makes indices read only if there is too little disk space. Also added collection of cluster_name as an item.</p>

<p>Please report issues at GitHub (easier to track progress there!)</p>

<p>https://github.com/yurtesen/zabbix_elasticsearch</p>

<p>Evren Yurtesen</p>

<h2 id="author">Author</h2>

<p>Evren Yurtesen</p>

<h2 id="macros-used">Macros used</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Default</th>
      <th>Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>{$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of fetch latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of flush latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HEAP_USED.MAX.CRIT}</td>
      <td>&lt;p&gt;The maximum percent in the use of JVM heap for critically trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">95</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HEAP_USED.MAX.WARN}</td>
      <td>&lt;p&gt;The maximum percent in the use of JVM heap for warning trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">85</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.HOST}</td>
      <td>&lt;p&gt;The hostname of the Elasticsearch host.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">localhost</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of indexing latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.PASSWORD}</td>
      <td>&lt;p&gt;The password of the Elasticsearch.&lt;/p&gt;</td>
      <td>``</td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.PORT}</td>
      <td>&lt;p&gt;The port of the Elasticsearch host.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">9200</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}</td>
      <td>&lt;p&gt;Maximum of query latency in milliseconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">100</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.RESPONSE_TIME.MAX.WARN}</td>
      <td>&lt;p&gt;The ES cluster maximum response time in seconds for trigger expression.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">10s</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.SCHEME}</td>
      <td>&lt;p&gt;The scheme of the Elasticsearch (http/https).&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">http</code></td>
      <td>Text macro</td>
    </tr>
    <tr>
      <td>{$ELASTICSEARCH.USERNAME}</td>
      <td>&lt;p&gt;The username of the Elasticsearch.&lt;/p&gt;</td>
      <td>``</td>
      <td>Text macro</td>
    </tr>
  </tbody>
</table>

<h2 id="template-links">Template links</h2>

<p>There are no template links in this template.</p>

<h2 id="discovery-rules">Discovery rules</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Type</th>
      <th>Key and additional info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cluster nodes discovery</td>
      <td>&lt;p&gt;Discovery ES cluster nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_nodes/_all/nodes,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1h&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>Index settings discovery</td>
      <td>&lt;p&gt;Discovery ES index settings&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.index.settings&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
  </tbody>
</table>

<h2 id="items-collected">Items collected</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Type</th>
      <th>Key and additional info</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ES: Number of non-deleted documents</td>
      <td>&lt;p&gt;The total number of non-deleted documents across all primary shards assigned to the selected nodes. This number is based on the documents in Lucene segments and may include the documents from nested fields.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.indices.docs.count&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get index settings</td>
      <td>&lt;p&gt;Returns index settings.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_settings,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the master role</td>
      <td>&lt;p&gt;The number of selected nodes with the master role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.master&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of data nodes</td>
      <td>&lt;p&gt;The number of nodes that are dedicated to data nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_data_nodes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get cluster health</td>
      <td>&lt;p&gt;Returns the health status of a cluster.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_cluster/health?timeout=5s,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get cluster stats</td>
      <td>&lt;p&gt;Returns cluster statistics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_cluster/stats,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Service status</td>
      <td>&lt;p&gt;Checks if the service is running and accepting TCP connections.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>net.tcp.service[”{$ELASTICSEARCH.SCHEME}”,”{$ELASTICSEARCH.HOST}”,”{$ELASTICSEARCH.PORT}”]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Task max waiting in queue</td>
      <td>&lt;p&gt;The time expressed in seconds since the earliest initiated task is waiting for being performed.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.task_max_waiting_in_queue&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster health status</td>
      <td>&lt;p&gt;Health status of the cluster, based on the state of its primary and replica shards. Statuses are: green All shards are assigned. yellow All primary shards are assigned, but one or more replica shards are unassigned. If a node in the cluster fails, some data could be unavailable until that node is repaired. red One or more primary shards are unassigned, so some data is unavailable. This can occur briefly during cluster startup as primary shards are assigned.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.status&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Total available size to JVM in all file stores</td>
      <td>&lt;p&gt;The total number of bytes available to JVM in the file stores across all selected nodes. Depending on OS or process-level restrictions, this number may be less than nodes.fs.free_in_byes. This is the actual amount of free disk space the selected Elasticsearch nodes can use.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.fs.available_in_bytes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of unassigned shards</td>
      <td>&lt;p&gt;The number of shards that are not allocated.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.unassigned_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster uptime</td>
      <td>&lt;p&gt;Uptime duration in seconds since JVM has last started.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.jvm.max_uptime[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Total size of all file stores</td>
      <td>&lt;p&gt;The total size in bytes of all file stores across all selected nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.fs.total_in_bytes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Service response time</td>
      <td>&lt;p&gt;Checks performance of the TCP service.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>net.tcp.service.perf[”{$ELASTICSEARCH.SCHEME}”,”{$ELASTICSEARCH.HOST}”,”{$ELASTICSEARCH.PORT}”]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of pending tasks</td>
      <td>&lt;p&gt;The number of cluster-level changes that have not yet been executed.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_pending_tasks&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of nodes</td>
      <td>&lt;p&gt;The number of nodes within the cluster.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.number_of_nodes&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Delayed unassigned shards</td>
      <td>&lt;p&gt;The number of shards whose allocation has been delayed by the timeout settings.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.delayed_unassigned_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of relocating shards</td>
      <td>&lt;p&gt;The number of shards that are under relocation.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.relocating_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the ingest role</td>
      <td>&lt;p&gt;The number of selected nodes with the ingest role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.ingest&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Number of initializing shards</td>
      <td>&lt;p&gt;The number of shards that are under initialization.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.initializing_shards&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Inactive shards percentage</td>
      <td>&lt;p&gt;The ratio of inactive shards in the cluster expressed as a percentage.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster.inactive_shards_percent_as_number&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Indices with shards assigned to nodes</td>
      <td>&lt;p&gt;The total number of indices with shards assigned to the selected nodes.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.indices.count&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Cluster name</td>
      <td>&lt;p&gt;Name of the cluster this node belongs to.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.cluster_name[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Get nodes stats</td>
      <td>&lt;p&gt;Returns cluster nodes statistics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Zabbix agent</code></td>
      <td>web.page.get[{$ELASTICSEARCH.HOST},_nodes/stats,{$ELASTICSEARCH.PORT}]&lt;p&gt;Update: 1m&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES: Nodes with the data role</td>
      <td>&lt;p&gt;The number of selected nodes with the data role.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.nodes.count.data&lt;p&gt;Update: 0&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency</td>
      <td>&lt;p&gt;The average flush latency calculated from the available flush.total and flush.total_time_in_millis metrics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.flush.latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency</td>
      <td>&lt;p&gt;The average fetch latency calculated by sampling the total number of fetches and the total elapsed time at regular intervals.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.search.fetch_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency</td>
      <td>&lt;p&gt;The average indexing latency calculated from the available index_total and index_time_in_millis metrics.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.indexing.index_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency</td>
      <td>&lt;p&gt;The average query latency calculated by sampling the total number of queries and the total elapsed time at regular intervals.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Calculated</code></td>
      <td>es.node.indices.search.query_latency[{#ES.NODE}]&lt;p&gt;Update: 1m&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total available size</td>
      <td>&lt;p&gt;The total number of bytes available to this Java virtual machine on all file stores. Depending on OS or process level restrictions, this might appear less than fs.total.free_in_bytes. This is the actual amount of free disk space the Elasticsearch node can utilize.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.fs.total.available_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the refresh thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing query</td>
      <td>&lt;p&gt;Time in milliseconds spent performing query operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of query</td>
      <td>&lt;p&gt;The total number of query operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Amount of JVM heap committed</td>
      <td>&lt;p&gt;The amount of memory, in bytes, available for use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_committed_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Maximum JVM memory available for use</td>
      <td>&lt;p&gt;The maximum amount of memory, in bytes, available for use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_max_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Amount of JVM heap currently in use</td>
      <td>&lt;p&gt;The memory, in bytes, currently in use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_used_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap currently in use</td>
      <td>&lt;p&gt;The percentage of memory currently in use by the heap.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.mem.heap_used_percent[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node uptime</td>
      <td>&lt;p&gt;JVM uptime in seconds.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.jvm.uptime[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the refresh thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the refresh thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the search thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the search thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the search thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.search.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool active threads</td>
      <td>&lt;p&gt;The number of active threads in the write thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.active[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor tasks completed</td>
      <td>&lt;p&gt;The number of tasks completed by the write thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.completed.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool tasks in queue</td>
      <td>&lt;p&gt;The number of tasks in queue for the write thread pool.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.queue[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing query</td>
      <td>&lt;p&gt;Time in seconds spent performing query operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of queries</td>
      <td>&lt;p&gt;The number of query operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current query operations</td>
      <td>&lt;p&gt;The number of query operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.query_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.throttle_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Number of open HTTP connections</td>
      <td>&lt;p&gt;The number of currently open HTTP connections for the node.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.http.current_open[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of HTTP connections opened</td>
      <td>&lt;p&gt;The number of HTTP connections opened for the node per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.http.opened.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of index flushes to disk</td>
      <td>&lt;p&gt;The total number of flush operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.flush.total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent on flushing indices to disk</td>
      <td>&lt;p&gt;Total time in milliseconds spent performing flush operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.flush.total_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current indexing operations</td>
      <td>&lt;p&gt;The number of indexing operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing indexing</td>
      <td>&lt;p&gt;Total time in milliseconds spent performing indexing operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of indexing</td>
      <td>&lt;p&gt;The total number of indexing operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.indexing.index_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling merge operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling merge operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.merges.total_throttled_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total size</td>
      <td>&lt;p&gt;Total size (in bytes) of all file stores.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.fs.total.total_in_bytes[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent throttling recovery operations</td>
      <td>&lt;p&gt;Time in seconds spent throttling recovery operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.recovery.throttle_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of index refreshes</td>
      <td>&lt;p&gt;The number of refresh operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.refresh.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing refresh</td>
      <td>&lt;p&gt;Time in seconds spent performing refresh operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.refresh.time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Rate of fetch</td>
      <td>&lt;p&gt;The number of fetch operations per second.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Current fetch operations</td>
      <td>&lt;p&gt;The number of fetch operations currently running.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_current[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Time spent performing fetch</td>
      <td>&lt;p&gt;Time in seconds spent performing fetch operations for the last measuring span.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_time[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total time spent performing fetch</td>
      <td>&lt;p&gt;Time in milliseconds spent performing fetch operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_time_in_millis[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Total number of fetch</td>
      <td>&lt;p&gt;The total number of fetch operations.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.indices.search.fetch_total[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor tasks rejected</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.node.thread_pool.write.rejected.rate[{#ES.NODE}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
    <tr>
      <td>ES {#ES.INDEX_NAME}: read_only_allow_delete</td>
      <td>&lt;p&gt;Elasticsearch enforces a read-only index block (index.blocks.read_only_allow_delete) on every index that has one or more shards allocated on the node that has at least one disk exceeding the flood stage.&lt;/p&gt;</td>
      <td><code class="language-plaintext highlighter-rouge">Dependent item</code></td>
      <td>es.index.read_only_allow_delete[{#ES.INDEX_NAME}]&lt;p&gt;Update: 0&lt;/p&gt;&lt;p&gt;LLD&lt;/p&gt;</td>
    </tr>
  </tbody>
</table>

<h2 id="triggers">Triggers</h2>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Description</th>
      <th>Expression</th>
      <th>Priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Read-only index “{#ES.INDEX_NAME}”</td>
      <td>&lt;p&gt;The index setting index.read_only_allow_delete is set to true when the index and index metadata are read only. It is set to false when ES allows writes and metadata changes. ES allows deleting the index to free up resources even when this setting is set to true.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.index.read_only_allow_delete[{#ES.INDEX_NAME}])=1&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency is too high (over {$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If you see this metric increasing steadily, it may indicate a problem with slow disks; this problem may escalate and eventually prevent you from being able to add new information to your index.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.flush.latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency is too high (over {$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If the latency is increasing, it may indicate that you are indexing too many documents at the same time (Elasticsearch’s documentation recommends starting with a bulk indexing size of 5 to 15 megabytes and increasing slowly from there).&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.indexing.index_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency is too high (over {$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;The fetch phase should typically take much less time than the query phase. If you notice this metric consistently increasing, this could indicate a problem with slow disks, enriching of documents (highlighting the relevant text in search results, etc.), or requesting too many results.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.fetch_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency is too high (over {$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}ms for 5m)</td>
      <td>&lt;p&gt;If latency exceeds a threshold, look for potential resource bottlenecks, or investigate whether you need to optimize your queries.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.query_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is critical (over {$ELASTICSEARCH.HEAP_USED.MAX.CRIT}% for 1h)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;95&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is high (over {$ELASTICSEARCH.HEAP_USED.MAX.WARN}% for 1h)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;85&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node {#ES.NODE} has been restarted (uptime &lt; 10m)</td>
      <td>&lt;p&gt;Uptime is less than 10 minutes&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.uptime[{#ES.NODE}])&lt;10m&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>information</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.search.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor has the rejected tasks (for 5m)</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.write.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Flush latency is too high (over {$ELASTICSEARCH.FLUSH_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If you see this metric increasing steadily, it may indicate a problem with slow disks; this problem may escalate and eventually prevent you from being able to add new information to your index.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.flush.latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Indexing latency is too high (over {$ELASTICSEARCH.INDEXING_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If the latency is increasing, it may indicate that you are indexing too many documents at the same time (Elasticsearch’s documentation recommends starting with a bulk indexing size of 5 to 15 megabytes and increasing slowly from there).&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.indexing.index_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Fetch latency is too high (over {$ELASTICSEARCH.FETCH_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;The fetch phase should typically take much less time than the query phase. If you notice this metric consistently increasing, this could indicate a problem with slow disks, enriching of documents (highlighting the relevant text in search results, etc.), or requesting too many results.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.fetch_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Query latency is too high (over {$ELASTICSEARCH.QUERY_LATENCY.MAX.WARN}ms for 5m) (LLD)</td>
      <td>&lt;p&gt;If latency exceeds a threshold, look for potential resource bottlenecks, or investigate whether you need to optimize your queries.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.indices.search.query_latency[{#ES.NODE}],5m)&gt;100&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is critical (over {$ELASTICSEARCH.HEAP_USED.MAX.CRIT}% for 1h) (LLD)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;95&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Percent of JVM heap in use is high (over {$ELASTICSEARCH.HEAP_USED.MAX.WARN}% for 1h) (LLD)</td>
      <td>&lt;p&gt;This indicates that the rate of garbage collection isn’t keeping up with the rate of garbage creation. To address this problem, you can either increase your heap size (as long as it remains below the recommended guidelines stated above), or scale out the cluster by adding more nodes.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.mem.heap_used_percent[{#ES.NODE}],1h)&gt;85&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Node {#ES.NODE} has been restarted (uptime &lt; 10m) (LLD)</td>
      <td>&lt;p&gt;Uptime is less than 10 minutes&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.node.jvm.uptime[{#ES.NODE}])&lt;10m&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>information</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Refresh thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the refresh thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.refresh.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Search thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the search thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.search.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>ES {#ES.NODE}: Write thread pool executor has the rejected tasks (for 5m) (LLD)</td>
      <td>&lt;p&gt;The number of tasks rejected by the write thread pool executor is over 0 for 5m.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: min(/App Elasticsearch Cluster by Zabbix agent/es.node.thread_pool.write.rejected.rate[{#ES.NODE}],5m)&gt;0&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>warning</td>
    </tr>
    <tr>
      <td>Read-only index “{#ES.INDEX_NAME}” (LLD)</td>
      <td>&lt;p&gt;The index setting index.read_only_allow_delete is set to true when the index and index metadata are read only. It is set to false when ES allows writes and metadata changes. ES allows deleting the index to free up resources even when this setting is set to true.&lt;/p&gt;</td>
      <td>&lt;p&gt;<strong>Expression</strong>: last(/App Elasticsearch Cluster by Zabbix agent/es.index.read_only_allow_delete[{#ES.INDEX_NAME}])=1&lt;/p&gt;&lt;p&gt;<strong>Recovery expression</strong>: &lt;/p&gt;</td>
      <td>high</td>
    </tr>
  </tbody>
</table>


    </div>
    
  </div>
  <script>
    (function () {
      
      //console.log('#content_ver_5_4');
      //console.log('#ver_5_4');
      $('.readme').hide();
      $('#content_ver_5_4').fadeIn('slow');
      $('#ver_5_4').addClass('active');

      
      $('#ver_5_0').click(function () {
        //console.log('#content_ver_5_0');
        //console.log('#ver_5_0');
        $('.readme').hide();
        $('#content_ver_5_0').fadeIn('slow');
        $('.js_tab').removeClass('active')
        $('#ver_5_0').addClass('active');
      })
      
      $('#ver_6_0').click(function () {
        //console.log('#content_ver_6_0');
        //console.log('#ver_6_0');
        $('.readme').hide();
        $('#content_ver_6_0').fadeIn('slow');
        $('.js_tab').removeClass('active')
        $('#ver_6_0').addClass('active');
      })
      
      $('#ver_5_4').click(function () {
        //console.log('#content_ver_5_4');
        //console.log('#ver_5_4');
        $('.readme').hide();
        $('#content_ver_5_4').fadeIn('slow');
        $('.js_tab').removeClass('active')
        $('#ver_5_4').addClass('active');
      })
      
    })();
  </script>
</body>

</html>